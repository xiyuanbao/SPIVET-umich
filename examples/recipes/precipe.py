"""
Filename:  precipe.py
Copyright (C) 2007-2010 William Newsome
 
This program is free software; you can redistribute it and/or
modify it under the terms of the GNU General Public License
as published by the Free Software Foundation; either version 2
of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details, published at 
http://www.gnu.org/copyleft/gpl.html

/////////////////////////////////////////////////////////////////
Description:
  This script is the primary recipe for image processing.  After
  running the script, a PIVData object containing rough flow field
  variables is created.  Other recipe scripts then proceed to refine
  these results.  The additional work could be incorporated here,
  however the conversion of images to velocity or temperature
  fields is the most time consuming part of the operation.  Hence we
  want to get these rough variables as quickly as possible and use
  other scripts to do additional processing.  That way if something 
  goes wrong with later scripts, we don't have to restart a 12-14 
  hour long process of converting images to flow field variables. 
  
  To execute the recipe after modifying as needed, just type
      python precipe.py
  into a terminal.  From here the recipe is fully automated.  The
  machine that submits a job will also provide status information
  as workers complete their jobs or run into errors.  A directory
  named OUTPUT will also be created that contains logs and PIVData
  files as they are generated by the workers.  Should a problem
  arise, checking the logs can help.
"""
from spivet import steps
from numpy import *

# These next two lines tell SPIVET to enable custom user-defined
# steps stored in a file named usersteps.py within the user's home 
# directory at the path .spivet/usersteps/usersteps.py.
steps.enable_user_steps()
import usersteps as usteps

# Build the pivdict dictionary.  Several functions along the way to
# converting raw images to flow field data need access to the same
# information.  Instead of repeatedly asking the user for this information
# it is stored in a dictionary that is then passed to SPIVET functions
# that need it.  For a detailed explanation of the pivdict parameters,
# see the documentation for the pivlib package:
#   import spivet
#   help(spivet.pivlib)
#
# A few notes are given here to explain the trickery below. The dewarpimg
# step can pad images for the user.  This padding can sometimes permit
# extraction of displacement vectors from regions of the image that would
# otherwise be too close to the edge.  Here we add a 16-pixel pad
# perimeter around all images.
#
# SPIVET also permits the user to specify a region of interest for
# processing.  This is convenient, since in many cases, we only want to
# extract vectors from a certain part of the image.  The region of
# interest is specified using the pivdict rbndx parameter (see pivlib
# package documentation).  Since we are using a camera calibration to
# project camera images back onto world coordinates (ie, laboratory
# coordinates), we need to specify the rbndx using the pixel dimensions of
# these dewarped images.  The dimensions of the dewarped images can
# be recorded during calibration, or they can also be retrieved from a 
# WICSP object (created during camera calibration) at any time thereafter.
# Simply use
#   from spivet import pivlib
#   wicsp = pivlib.pklload("PATH TO A WICSP")
#   print wicsp['wpxdim']
# See documentation on pivlib.pivpg.wrld2imcsp for more on the contents
# of the WICSP object.
wicsp = ['ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/SYRUPCAL-06132008/CALIBRATION/WICSP_CAM0',
'ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/SYRUPCAL-06132008/CALIBRATION/WICSP_CAM1']
camcal = ['ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/SYRUPCAL-06132008/CALIBRATION/CAMCAL_CAM0',
'ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/SYRUPCAL-06132008/CALIBRATION/CAMCAL_CAM1']
tlccal = 'ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/TLCCAL-09282008/TLCCALIBRATION/TLCCAL_CAM1'

padpix = 16
imdim  = array([1357, 1030]) +2*array([padpix,padpix])
drbndx = array([[70+padpix,-39-padpix],
                [35+padpix,-35-padpix]])
rbndx  = array([[0,imdim[0]],[0,imdim[1]]]) +drbndx

pivdict={
    'gp_rbndx':rbndx,
    'gp_bsize':(32,32),
    'gp_bolap':(0,0),
    'gp_bsdiv':2,
    'ir_eps':0.003,
    'ir_maxits':100, 
    'ir_mineig':0.05,
    'ir_imthd':'C',
    'ir_iedge':0,
    'ir_tps_csrp':0.1,
    'ir_tps_ithp':90,
    'ir_tps_wsize':[5,5],
    'ir_tps_sdmyf':0.1,
    'ir_tps_alpha':0.8,
    'ir_tps_beta':1.5,
    'ir_tps_csize':15,
    'ir_tps_nits':30,
    'ir_tps_scit':5,
    'ir_tps_annl':0.98,
    'of_maxdisp':(34,34), 
    'of_rmaxdisp':(5,5), 
    'of_hrsc':False,
    'of_nccth':0.7,
    'of_highp':False,
    'of_bsdcmx':0.,
    'pg_wicsp':wicsp,
    'pg_camcal':camcal,
    'tc_tlccal':tlccal,
    'tc_tlccam':1,
    'tc_ilvec':[0.,0.,-1.],
    'tc_interp':False
}

# Now we start creating configuration objects for the various steps this
# recipe will run.  The operations performed by the steps can be found
# in the steps module documentation.
#
# It's good practice to list the configurations in the order in which
# they are run, since it's easier to keep track of what's happening that
# that way.

# CONFIG: loadimg
# This step loads the images specified in those EFRMLST files created
# using the bldsched recipe.
conf_loadimg = {'rgb':True}

# CONFIG: coloradj (*** userstep ***)
# This step is a custom userstep not provided with the SPIVET library.
# It's shown here just as a reminder that these steps are processed
# like any others.  To setup the configuration, the next two lines would
# obviously not be commented out.  
#adjmat = 'ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/COLORADJ/COLORADJ'
#conf_coloradj = {'adjmat':adjmat}

# CONFIG: dewarpimg
# This step applies the camera calibration to project the images
# back onto world coordinates.
conf_dewarpimg = {'wicsp':wicsp,'camcal':camcal,'padpix':padpix}

# CONFIG: oflow2d
# This step will compute optical flow on the projected images.
conf_oflow2d = {'pivdict':pivdict}

# CONFIG: pdmedfltr
# Apply the first of three spurious vector removal tools.  We first
# apply a 3x3 filter.  This filter isn't very effective at removing
# clusters of bad displacement vectors, but it does help prevent the
# larger filter applied next from erroneously smoothing out too much
# fine scale structure.  Each user should test the optimum filter set
# that works for their data.
conf_pdmedfltr3 = {'varnm':['R0','R1'],
                  'planar':True,
                  'rthsf':4.,
                  'reps':0.1,
                  'mfits':3,
                  'mfdim':3,
                  'pdname':'pivdata'}

# CONFIG: pdmedfltr
# The second median filter spurious vector removal tool.  This time
# the filter is run using a 5x5 window.
#
# One other item of interest.  The variable to be filtered is specified
# by the 'varnm' configuration parameter.  Comparing the configuration
# dictionary below to the previous one shows an important characteristic
# of most steps: data is not thrown away.  The previous filtering step
# operated on the variables named 'R0' and 'R1', and in the process
# generated the 'R0-MF' and 'R1-MF' (MF for Median Filtered) that the
# current step will operate on.  This is an important property of SPIVET
# steps.  Once the output of precipe is stored at the end of the script
# below, the user can load the PIVDATA.ex2 file in Paraview, say, and see
# exactly how each filter changed the data.  If the current filter is
# too strong, then the original data is still available and can easily
# be reprocessed. 
conf_pdmedfltr5 = {'varnm':['R0-MF','R1-MF'],
                  'planar':True,
                  'rthsf':4.,
                  'reps':0.1,
                  'mfits':3,
                  'mfdim':5,
                  'pdname':'pivdata'}

# CONFIG: pdgsmooth
# The last filter tool.  Here we apply a standard Gaussian filter to
# smooth the results.  Generally, such smoothing should be discouraged.
# Here, however, the smooth results are input into an iterative refinement
# scheme.  Hence the smoothed results are an initial guess that will be
# refined later.
conf_pdgsmooth = {'varnm':['R0-MF-MF','R1-MF-MF'],
                  'planar':True,
                  'gbsd':1.,
                  'pdname':'pivdata'}

# CONFIG: refine2dof
# This step iteratively refines the 2D displacement vectors by warping
# the images until the tracers line up.  See the step documentation for
# more details.  The method used is somewhat akin to other window deformation
# schemes in the PIV literature.
#
# Note that we take a copy here of the pivdict dictionary created above.
# The reason for doing so is that it might be beneficial to change some
# pivdict parameters just for the iterative refinement only.  In this 
# recipe, no pivdict parameters have been adjusted, but the copy is left 
# just in case changes might be wanted in the future.
mf3d = {'filter':'medfltr','fdim':3,'rthsf':5.,'reps':0.1,'planar':True,'nit':3,
        'cndx':None}
mf5d = {'filter':'medfltr','fdim':5,'rthsf':6.,'reps':0.1,'planar':True,'nit':3,
        'cndx':None}
gsd = {'filter':'gsmooth','gbsd':1.,'planar':True,'nit':1,'cndx':None}

rpivdict = pivdict.copy()

ifurl = "ftp://10.45.77.2/globalstore/Projects/PIV/Datasets/R2DIMGFLTR/R2DIMGFLTR"

conf_refine2dof = {'pivdict':rpivdict,
                   'varnm':['R0-MF-MF-GS','R1-MF-MF-GS'],
                   'crbndx':pivdict['gp_bsdiv']*array([[27,39],[8,30-8]]),
                   'rfactor':1.2,
                   'its':10,
                   'eps':0.01,
                   'planes':range(21,28),
                   'cfltrprm':[mf3d,mf5d,gsd],
                   'ifltr':[ifurl,ifurl]}

# CONFIG: oflow3d
# Now that two iteratively refined flow fields are available, one from each
# camera, we can reconstruct the 3D flow field.
conf_oflow3d = {'pivdict':pivdict,
                'varnms':['R0-MF-MF-GS-TR','R1-MF-MF-GS-TR','R0INAC','R1INAC'],
                'zcellsz':-5.0}

# CONFIG: disp2vel
# Displacements computed up to this point have units of pixels or mm.
# We want velocities, so this step converts 3D displacements into velocities.
# SPIVET can do this because a timestamp is baked into the filename of
# each image file.  Note also that this step has an empty configuration
# dictionary.
conf_disp2vel = {}

# CONFIG: recordtime
# This step is a utility step that simply stores the timestamps in
# the PIVData object.  Having these timestamps as a standard PIV variable
# (equivalent to velocity or temperature) is handy.
conf_recordtime = {}

# CONFIG: bimedfltr
# Most of the previous steps have been geared toward extracting
# the displacment/velocity field.  This is the first step geared toward
# extracting temperature from TLC's.  This step is important for the 
# Univ. of Michigan experiments because TLC's and another type of particle
# are simultaneously used as tracers.  The secondary tracer particles
# need to be removed from the images with this step before we compute the 
# TLC hue.
conf_bimedfltr = {'rbndx':pivdict['gp_rbndx'],
                  'bsize':pivdict['gp_bsize'],
                  'prccam':[False,True],
                  'prcchnl':[True,False,False]}

# CONFIG: tlcmask
# This step applies a set of heuristics to mask out what are considered
# to be 'valid' TLC particles.  These valid particles are then used to
# compute the hue for the block in question.
conf_tlcmask = {'pivdict':pivdict,
                'prccam':[False,True]}

# CONFIG: sctfcomp
# This is the primary step for converting TLC hue to temperature.
conf_sctfcomp = {'pivdict':pivdict,
                 'zcellsz':-5.0,
                 'tlcp0swz':15.}

# CONFIG: loop_plane
# The SPIVET steps framework provides two special container steps that
# execute other steps repeatedly.  This particular container executes
# all of its child steps on every z-plane within an Epoch (ie, for every
# line of one EFRMLST file).  The commented out step is for the
# userstep discussed above.  Again it's included here just to show how
# usersteps are passed.
#
# The loop_plane step will automatically combine the results from
# the individual planes into one aggregate PIVData object.
conf_loop_plane = {'steps':[['loadimg','spivet.steps',conf_loadimg],
                            #['coloradj','usersteps',conf_coloradj],
                            ['dewarpimg','spivet.steps',conf_dewarpimg],
                            ['oflow2d','spivet.steps',conf_oflow2d],
                            ['medfltr','spivet.steps',conf_pdmedfltr3],
                            ['medfltr','spivet.steps',conf_pdmedfltr5],
                            ['gsmooth','spivet.steps',conf_pdgsmooth],
                            ['refine2dof','spivet.steps',conf_refine2dof],
                            ['oflow3d','spivet.steps',conf_oflow3d],
                            ['disp2vel','spivet.steps',conf_disp2vel],
                            ['recordtime','spivet.steps',conf_recordtime],
                            ['bimedfltr','spivet.steps',conf_bimedfltr],
                            ['tlcmask','spivet.steps',conf_tlcmask],
                            ['sctfcomp','spivet.steps',conf_sctfcomp]]}

# From this point on, we need to think in terms of working on all the
# data for a given Epoch.  The conf_loop_plane step has combined planar
# results into Epoch results.

# CONFIG: ptmedfltr
# This step applies the spurious vector removal tool to the temperature
# field!  This filter tool is very handy for removing any type of 
# spurious data.
conf_ptmedfltr = {'varnm':['T'],
                  'planar':True,
                  'rthsf':2.,
                  'reps':0.15,
                  'mfits':1,
                  'mfdim':9,
                  'pdname':'epivdata'}

# CONFIG: loop_epoch
# This step represents the second special container step of the SPIVET
# framework.  It loops over all the Epochs (ie, over all the individual
# EFRMLST files.  This is the step that also provides for parallel
# processing.  All the preceeding steps are run on a single processor.  
# This step will dispatch processing of different Epochs to different
# processors or machines.
#
# When setting up a recipe for the first time, it is highly recommended
# that the user test the setup on a single machine using a smaller
# set of images (maybe for a few planes of just one Epoch only).
#
# SPIVET does try to fail gracefully should problems occur when running
# in parallel.  In those unfortunate cases, SPIVET will alert that an
# Epoch failed and keep processing results.  The problematic EFRMLST
# files alone can then be fed back to SPIVET later and the results 
# combined using the assembly step.
conf_loop_epoch = {'steps':[['loop_plane','spivet.steps',conf_loop_plane],
                            ['medfltr','spivet.steps',conf_ptmedfltr]],
                   'parallel':True}

# Building the configuration dictionaries is complete.  We still need to
# setup the carriage.  Here we are using the loop_epoch container step,
# and it is a sort of master step.  So all we need to do is set up the
# carriage for the loop_epoch step, and it will take care of everyting
# else.
carriage = {'lbfpath':'EFRMLSTS'}

# Execute.  Again, the loop_epoch step is a kind of master step, so we
# only need to instantiate, configure, set the carriage, and execute the
# loop_epoch step.    
t = steps.loop_epoch()
t.setConfig(conf_loop_epoch)
t.setCarriage(carriage)
t.execute()

# Once the processing is complete the carriage will contain an entry
# under the name 'dpivdata' containing the PIVData object for the frame
# group of interest (see documentation of the loop_epoch step). In most
# cases, the user will only have one frame group, hence the 0 in the
# following line.  
pd = carriage['dpivdata'][0]
pd.save('PIVDATA.ex2')  # Save the full PIVData object to a file.
